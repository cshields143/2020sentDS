{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environs import Env\n",
    "import tweepy\n",
    "import datetime as dt\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our Twitter authentication info from environment variables\n",
    "\n",
    "env = Env()\n",
    "env.read_env()\n",
    "TWITTER_KEY = env.str('TWITTER_KEY')\n",
    "TWITTER_SECRET = env.str('TWITTER_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection to Twitter's API\n",
    "\n",
    "auth = tweepy.AppAuthHandler(TWITTER_KEY, TWITTER_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class will be used to hold the individual tweets from our search;\n",
    "# it also does some sprucing up of the tweet and meta data extraction\n",
    "\n",
    "class MyTweet:\n",
    "    def __init__(self, tweet):\n",
    "        \n",
    "        # all of the features of tweets that we're tracking,\n",
    "        # and where we're getting them from (store them as a\n",
    "        # dictionary to make pandas-ifying easier)\n",
    "        \n",
    "        is_retweet = self.check_for_retweet(tweet.full_text)\n",
    "        \n",
    "        self.features = dict(\n",
    "            id=tweet.id,\n",
    "            account=tweet.author.name,\n",
    "            account_screenname=tweet.user.screen_name,\n",
    "            account_location=self.get_user_location(tweet.user.location),\n",
    "            account_followers=tweet.author.followers_count,\n",
    "            account_following=tweet.author.friends_count,\n",
    "            account_age_days=self.get_account_age(tweet.author.created_at),\n",
    "            account_description=self.parse_profile_description(tweet.author.description),\n",
    "            is_retweet=is_retweet,\n",
    "            original_author=self.get_original_author(tweet.full_text) if is_retweet else tweet.user.screen_name,\n",
    "            tweeted_on=tweet.created_at,\n",
    "            count_retweeted=tweet.retweet_count,\n",
    "            count_favorited=tweet.favorite_count,\n",
    "            hashtags=self.get_hashtags(tweet.entities.get('hashtags')),\n",
    "            tweet_text=self.get_full_text(tweet.full_text) if is_retweet else tweet.full_text\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "# these methods are used to extract/clean data from the tweet\n",
    "    \n",
    "    # use NaN for location if none is provided\n",
    "    @staticmethod\n",
    "    def get_user_location(loc):\n",
    "        return float('nan') if loc == '' else loc\n",
    "    \n",
    "    # how old is the user's account (in days)?\n",
    "    @staticmethod\n",
    "    def get_account_age(created_at):\n",
    "        today = dt.datetime.today()\n",
    "        diff = today - created_at\n",
    "        return abs(diff).days\n",
    "    \n",
    "    # use NaN for the profile description if none is provided\n",
    "    @staticmethod\n",
    "    def parse_profile_description(txt):\n",
    "        return float('nan') if txt == '' else txt\n",
    "    \n",
    "    # is this a retweet of someone else (using 1/0 for y/n)?\n",
    "    @staticmethod\n",
    "    def check_for_retweet(txt):\n",
    "        return 1 if txt[:2] == 'RT' else 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # extract the original author of a retweet\n",
    "    @staticmethod\n",
    "    def get_original_author(txt):\n",
    "        \n",
    "        # hopefully this regular expression will work\n",
    "        try:\n",
    "            pattern = '(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z0-9-_]+)'\n",
    "            return re.findal(pattern, txt)\n",
    "        \n",
    "        # nuts, we have to do it by hand\n",
    "        except:\n",
    "            return txt.split('RT')[-1].split(':')[0].replace(' ', '')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # extract all of the #hashtags from the tweet, storing them all\n",
    "    # in a single comma-separated string (use NaN if there aren't any)\n",
    "    @staticmethod\n",
    "    def get_hashtags(htags):\n",
    "        return float('nan') if len(htags) == 0 else ','.join(t['text'] for t in htags)\n",
    "    \n",
    "    # get the full text of a retweet, excluding all the \"RT\" stuff\n",
    "    @staticmethod\n",
    "    def get_full_text(txt):\n",
    "        return re.sub(r'^RT[^:]*:\\w*', '', txt)\n",
    "\n",
    "\n",
    "\n",
    "# helper for making a pandas dataframe out of this\n",
    "    def to_dict(self):\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and this class will be the bucket that all of our\n",
    "# individual tweets are stored in\n",
    "\n",
    "class MyTweetBucket:\n",
    "    def __init__(self):\n",
    "        self.tweets = []\n",
    "        self.ids = set()\n",
    "    \n",
    "    def add_tweet(self, tweet):\n",
    "        \n",
    "        # don't add a tweet that we already have\n",
    "        if tweet.id not in self.ids:\n",
    "            tweet = MyTweet(tweet)\n",
    "            self.ids.add(tweet.features['id'])\n",
    "            self.tweets.append(tweet)\n",
    "    \n",
    "    # when the searching & adding is done, turn this\n",
    "    # giant set of tweets into a pandas dataframe\n",
    "    def to_pd(self):\n",
    "        return pd.DataFrame(t.to_dict() for t in self.tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:50<00:00,  6.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Get a nice sample of tweets that are about the election\n",
    "\n",
    "election_tweets = MyTweetBucket()\n",
    "\n",
    "# each of these queries will be a different call to the Twitter API\n",
    "search_terms = [\n",
    "    '#election2020',\n",
    "    'trump',\n",
    "    'biden',\n",
    "    '#maga',\n",
    "    '#vote',\n",
    "    '#election',\n",
    "    '#democrat',\n",
    "    '#resist',\n",
    "    '#voteblue',\n",
    "    '#impotus',\n",
    "    '#getoutthevote',\n",
    "    '#gop',\n",
    "    '#republican',\n",
    "    '#politics',\n",
    "    '#liberal',\n",
    "    '#conservative',\n",
    "    '#bluewave'\n",
    "]\n",
    "\n",
    "for term in tqdm(search_terms):\n",
    "    \n",
    "    # our \"cursor\", ie, the results of this particular search\n",
    "    curs = tweepy.Cursor(api.search, q=term, tweet_mode='extended')\n",
    "    \n",
    "    # only collect up to 200 tweets from this search\n",
    "    for tweet in curs.items(200):\n",
    "        election_tweets.add_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:10<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# STEP 2a: Get a sample of \"known\" pro-Trump tweets\n",
    "\n",
    "trump_tweets = MyTweetBucket()\n",
    "\n",
    "# we assume that these users are consistently pro-Trump\n",
    "trump_users = [\n",
    "    'realDonaldTrump',\n",
    "    'Mike_Pence',\n",
    "    'Team_Trump45',\n",
    "    'DiamondandSilk',\n",
    "    'DonnaWR8',\n",
    "    'The_Trump_Train',\n",
    "    'joegooding',\n",
    "    'paultdove',\n",
    "    'Filibuster',\n",
    "    'Bet22325450ste',\n",
    "    'JerryTravone',\n",
    "    'Fuctupmind'\n",
    "]\n",
    "\n",
    "for username in tqdm(trump_users):\n",
    "    \n",
    "    # if the user doesn't exist, then don't worry about it\n",
    "    try:\n",
    "        user = api.get_user(username, tweet_mode='extended')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # remember to only get 200\n",
    "    for tweet in user.timeline(count=200, tweet_mode='extended'):\n",
    "        trump_tweets.add_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:11<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# STEP 2b: Get a sample of \"known\" pro-Biden tweets\n",
    "\n",
    "biden_tweets = MyTweetBucket()\n",
    "\n",
    "# again, just assume these are all always pro-Biden\n",
    "biden_users = [\n",
    "    'JoeBiden',\n",
    "    'KamalaHarris',\n",
    "    'benbrown',\n",
    "    'biden4pres',\n",
    "    'RepsForBiden',\n",
    "    'joncoopertweets',\n",
    "    'AndrewBatesNC',\n",
    "    'TeamJoe',\n",
    "    'RealKHiveQueenB',\n",
    "    'YAFBiden',\n",
    "    'ProfSybill'\n",
    "    'JoeKamalaTicket',\n",
    "]\n",
    "\n",
    "for username in tqdm(biden_users):\n",
    "    \n",
    "    # skip non-existent users\n",
    "    try:\n",
    "        user = api.get_user(username, tweet_mode='extended')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # only get 200 tweets\n",
    "    for tweet in user.timeline(count=200, tweet_mode='extended'):\n",
    "        biden_tweets.add_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results of our searches\n",
    "election_tweets.to_pd().to_csv('../data/raw/election-tweets-initial.csv', index=False)\n",
    "trump_tweets.to_pd().to_csv('../data/raw/pro-trump-tweets.csv', index=False)\n",
    "biden_tweets.to_pd().to_csv('../data/raw/pro-biden-tweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
